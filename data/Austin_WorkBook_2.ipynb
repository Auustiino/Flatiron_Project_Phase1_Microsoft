{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: data/zippedData: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "os.system(\"ls data/zippedData | grep sv > file_list.txt\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dict.keys>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('file_list.txt', 'r') as f:\n",
    "    csv_list= f.readlines()\n",
    "file_dict = {}\n",
    "for csv in csv_list:\n",
    "    key='ZippedData/'+csv.strip()\n",
    "    df_name=csv.strip()\n",
    "    df_name=df_name.split('.csv.gz')[0]\n",
    "    df=pd.read_csv(key, compression='gzip')\n",
    "    file_dict[df_name] = df\n",
    "file_dict.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bom.movie_gross.csv.gz\r\n",
      "imdb.name.basics.csv.gz\r\n",
      "imdb.title.akas.csv.gz\r\n",
      "imdb.title.basics.csv.gz\r\n",
      "imdb.title.crew.csv.gz\r\n",
      "imdb.title.principals.csv.gz\r\n",
      "imdb.title.ratings.csv.gz\r\n",
      "tmdb.movies.csv.gz\r\n",
      "tmdb_genres.csv.gz\r\n",
      "tmdb_imdb_gross.csv.gz\r\n",
      "tmdb_imdb_gross_full.csv\r\n",
      "tmdb_imdb_gross_test.csv.gz\r\n",
      "tmdb_movie_ids.csv.gz\r\n",
      "tn.movie_budgets.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls zippedData | grep csv > file_list.txt\n",
    "!cat file_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie</th>\n",
       "      <th>production_budget</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>worldwide_gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dec 18, 2009</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>$425,000,000</td>\n",
       "      <td>$760,507,625</td>\n",
       "      <td>$2,776,345,279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  release_date   movie production_budget domestic_gross worldwide_gross\n",
       "0   1  Dec 18, 2009  Avatar      $425,000,000   $760,507,625  $2,776,345,279"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_budgets = pd.read_csv('zippedData/tn.movie_budgets.csv.gz', compression = 'gzip')\n",
    "# budgets.info()\n",
    "tn_budgets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>12444</td>\n",
       "      <td>en</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>33.533</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        genre_ids     id original_language  \\\n",
       "0           0  [12, 14, 10751]  12444                en   \n",
       "\n",
       "                                 original_title  popularity release_date  \\\n",
       "0  Harry Potter and the Deathly Hallows: Part 1      33.533   2010-11-19   \n",
       "\n",
       "                                          title  vote_average  vote_count  \n",
       "0  Harry Potter and the Deathly Hallows: Part 1           7.7       10788  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_movies = pd.read_csv('zippedData/tmdb.movies.csv.gz', compression = 'gzip')\n",
    "tmdb_movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bom.movie_gross'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [376]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bom_budgets \u001b[38;5;241m=\u001b[39m \u001b[43mfile_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbom.movie_gross\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bom.movie_gross'"
     ]
    }
   ],
   "source": [
    "bom_budgets = file_dict['bom.movie_gross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^^^^^^^^^^BUDGETS^^^^^^^^^^^^BUDGETS^^^^^^^^^^^^BUDGETS^^^^^^^^^^^^BUDGETS^^^^^^^^^^^^BUDGETS^^^^^^^^^^^^BUDGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROTTEN TOMATOES CRITIC WORKING --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0.5/10',\n",
       " '0.5/4',\n",
       " '0.5/5',\n",
       " '0/10',\n",
       " '0/4',\n",
       " '0/5',\n",
       " '0/6',\n",
       " '1',\n",
       " '1-5',\n",
       " '1.0',\n",
       " '1.0/4',\n",
       " '1.0/5',\n",
       " '1.5',\n",
       " '1.5/10',\n",
       " '1.5/4',\n",
       " '1.5/5',\n",
       " '1.6/5',\n",
       " '1.8',\n",
       " '1.9/5',\n",
       " '1/10',\n",
       " '1/2',\n",
       " '1/4',\n",
       " '1/5',\n",
       " '1/6',\n",
       " '2',\n",
       " '2.0/4',\n",
       " '2.0/5',\n",
       " '2.1/2',\n",
       " '2.2',\n",
       " '2.2/5',\n",
       " '2.3/10',\n",
       " '2.3/4',\n",
       " '2.3/5',\n",
       " '2.4/5',\n",
       " '2.5',\n",
       " '2.5/10',\n",
       " '2.5/4',\n",
       " '2.5/5',\n",
       " '2.6/5',\n",
       " '2.6/6',\n",
       " '2.7',\n",
       " '2.7/5',\n",
       " '2/10',\n",
       " '2/2',\n",
       " '2/4',\n",
       " '2/5',\n",
       " '2/6',\n",
       " '3',\n",
       " '3 1/2',\n",
       " '3.0',\n",
       " '3.0/10',\n",
       " '3.0/4',\n",
       " '3.0/5',\n",
       " '3.1',\n",
       " '3.1/5',\n",
       " '3.2',\n",
       " '3.3',\n",
       " '3.3/5',\n",
       " '3.4',\n",
       " '3.5',\n",
       " '3.5/10',\n",
       " '3.5/4',\n",
       " '3.5/5',\n",
       " '3.6/5',\n",
       " '3.7',\n",
       " '3.7/5',\n",
       " '3.8/10',\n",
       " '3.8/5',\n",
       " '3/10',\n",
       " '3/2',\n",
       " '3/4',\n",
       " '3/5',\n",
       " '3/6',\n",
       " '4',\n",
       " '4.0',\n",
       " '4.0/10',\n",
       " '4.0/4',\n",
       " '4.0/5',\n",
       " '4.1',\n",
       " '4.1/10',\n",
       " '4.2',\n",
       " '4.2/10',\n",
       " '4.2/5',\n",
       " '4.3/10',\n",
       " '4.3/5',\n",
       " '4.4/5',\n",
       " '4.5',\n",
       " '4.5/10',\n",
       " '4.5/5',\n",
       " '4.7',\n",
       " '4.8',\n",
       " '4.9',\n",
       " '4.9/10',\n",
       " '4/10',\n",
       " '4/4',\n",
       " '4/5',\n",
       " '4/6',\n",
       " '5',\n",
       " '5.0/10',\n",
       " '5.0/5',\n",
       " '5.2',\n",
       " '5.5/10',\n",
       " '5.5/5',\n",
       " '5.8',\n",
       " '5.8/10',\n",
       " '5.9',\n",
       " '5.9/10',\n",
       " '5/10',\n",
       " '5/5',\n",
       " '5/6',\n",
       " '6',\n",
       " '6.0/10',\n",
       " '6.2',\n",
       " '6.2/10',\n",
       " '6.3/10',\n",
       " '6.5/10',\n",
       " '6.7',\n",
       " '6.8/10',\n",
       " '6.9/10',\n",
       " '6/10',\n",
       " '6/8',\n",
       " '7',\n",
       " '7.0/10',\n",
       " '7.1',\n",
       " '7.1/10',\n",
       " '7.2/10',\n",
       " '7.3',\n",
       " '7.3/10',\n",
       " '7.4',\n",
       " '7.4/10',\n",
       " '7.5/10',\n",
       " '7.6/10',\n",
       " '7.7',\n",
       " '7.7/10',\n",
       " '7.8',\n",
       " '7.8/10',\n",
       " '7.9',\n",
       " '7.9/10',\n",
       " '7/10',\n",
       " '8',\n",
       " '8.0/10',\n",
       " '8.1/10',\n",
       " '8.2',\n",
       " '8.2/10',\n",
       " '8.3/10',\n",
       " '8.4',\n",
       " '8.4/10',\n",
       " '8.5',\n",
       " '8.5/10',\n",
       " '8.6/10',\n",
       " '8.7/10',\n",
       " '8.8/10',\n",
       " '8.9',\n",
       " '8.9/10',\n",
       " '8/10',\n",
       " '9',\n",
       " '9.0',\n",
       " '9.0/10',\n",
       " '9.2',\n",
       " '9.2/10',\n",
       " '9.5/10',\n",
       " '9.6/10',\n",
       " '9.7',\n",
       " '9.8',\n",
       " '9/10',\n",
       " 'A',\n",
       " 'A+',\n",
       " 'A-',\n",
       " 'B',\n",
       " 'B+',\n",
       " 'B-',\n",
       " 'C',\n",
       " 'C+',\n",
       " 'C-',\n",
       " 'D',\n",
       " 'D+',\n",
       " 'D-',\n",
       " 'F',\n",
       " 'F+',\n",
       " 'F-',\n",
       " 'T']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROTTEN TOMATOES CRITIC RATING FOR MERGING\n",
    "\n",
    "# rt_reviews = pd.read_csv('zippedData/rt.reviews.tsv.gz',sep = '\\t', compression = 'gzip', encoding = 'latin-1' )\n",
    "# rt_reviews.head()\n",
    "# rt_reviews_clean.info() #34k non_null\n",
    "# len(pd.unique(rt_reviews_clean['id'])) #1055 individual id \n",
    "# rt_reviews_clean.head(1)\n",
    "# len(pd.unique(rt_reviews_cleaned['id']))\n",
    "\n",
    "\n",
    "\n",
    "rt_reviews_cleaned = rt_reviews_clean[['id', 'rating', 'critic']]\n",
    "\n",
    "rt_reviews_cleaned.head(1)\n",
    "\n",
    "sorted(rt_reviews_cleaned['rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>director</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>William Friedkin</td>\n",
       "      <td>104 minutes</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          director      runtime rating\n",
       "0   1  William Friedkin  104 minutes      R"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROTTEN TOMATOES DIRECTOR/RUNTIME INFO FOR MERGING\n",
    "\n",
    "# rt_movie_info = pd.read_csv('zippedData/rt.movie_info.tsv.gz',sep = '\\t', compression = 'gzip', encoding = 'latin-1' )\n",
    "# rt_reviews_info = rt_movie_info[['id', 'director', 'runtime', 'rating']]\n",
    "# len(pd.unique(rt_movie_info['id'])) #1560 individual id\n",
    "# rt_movie_info.head(10)\n",
    "# rt_movie_info.info() #\n",
    "# rt_reviews_info = rt_movie_info[['id', 'director', 'runtime', 'rating']]\n",
    "\n",
    "# rt_reviews_info = rt_reviews_info.dropna()\n",
    "# len(rt_reviews_info)\n",
    "\n",
    "rt_reviews_info.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>director</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rating_x</th>\n",
       "      <th>rating_y</th>\n",
       "      <th>critic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>David Cronenberg</td>\n",
       "      <td>108 minutes</td>\n",
       "      <td>R</td>\n",
       "      <td>3/5</td>\n",
       "      <td>PJ Nabarro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          director      runtime rating_x rating_y      critic\n",
       "0   3  David Cronenberg  108 minutes        R      3/5  PJ Nabarro"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROTTEN TOMATOE ID DIRECTOT RUNTIME RATING COMBINED---- READY FOR CLEANING\n",
    "\n",
    "rt_df = rt_reviews_info.merge(rt_reviews_cleaned, how = 'inner', on = 'id')\n",
    "# rt_df[100:140]\n",
    "# len(pd.unique(rt_df['director'])) #938 unique id ---- 781 unique directors\n",
    "rt_df.head(1)\n",
    "# rt_df.info()\n",
    "\n",
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NORMALIZING RATINGS\n",
    "\n",
    "def norm_ratings(rating):\n",
    "    grades = {\"A\":10,\"B\":8,\"C\":6,\"D\":4,\"F\":2,\"A+\":10,\"B+\":9,\"C+\":7,\"D+\":5,\\\n",
    "              \"F+\":3,\"A-\":9,\"B-\":7,\"C-\":5,\"D-\":3,\"F-\":0, '3 1/2': 3.5, 'T': None}\n",
    "    \n",
    "    if rating in grades.keys():\n",
    "        norm=grades[rating]\n",
    "        return norm\n",
    "    elif ('/') in rating:\n",
    "        r = rating.split('/')\n",
    "        norm = float(r[0])/float(r[1])*10\n",
    "        return norm\n",
    "    elif ('-') in rating and len(rating) > 2:\n",
    "        r = rating.split('-')\n",
    "        norm = float(r[0])/float(r[1])*10\n",
    "        return norm\n",
    "    else:\n",
    "        norm = float(rating)\n",
    "        return norm\n",
    "\n",
    "    \n",
    "norm_ratings('')\n",
    "    \n",
    "# rt_df['critic_rating'] = rt_df['rating_y'].apply(norm_ratings)\n",
    "# DROPPING SINGLE NONE RATING\n",
    "\n",
    "# rt_df = rt_df.dropna()\n",
    "# rt_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING RUNTIME \n",
    "def clean_runtime(runtime):\n",
    "    minutes = runtime.split()[0]\n",
    "    return int(minutes)\n",
    "\n",
    "# rt_df['runtime'] = rt_df['runtime'].apply(clean_runtime)\n",
    "\n",
    "# rt_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>primary_name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>death_year</th>\n",
       "      <th>primary_profession</th>\n",
       "      <th>known_for_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0061671</td>\n",
       "      <td>Mary Ellen Bauder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miscellaneous,production_manager,producer</td>\n",
       "      <td>tt0837562,tt2398241,tt0844471,tt0118553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0061865</td>\n",
       "      <td>Joseph Bauer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>composer,music_department,sound_department</td>\n",
       "      <td>tt0896534,tt6791238,tt0287072,tt1682940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0062070</td>\n",
       "      <td>Bruce Baum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miscellaneous,actor,writer</td>\n",
       "      <td>tt1470654,tt0363631,tt0104030,tt0102898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0062195</td>\n",
       "      <td>Axel Baumann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>camera_department,cinematographer,art_department</td>\n",
       "      <td>tt0114371,tt2004304,tt1618448,tt1224387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0062798</td>\n",
       "      <td>Pete Baxter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production_designer,art_department,set_decorator</td>\n",
       "      <td>tt0452644,tt0452692,tt3458030,tt2178256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst       primary_name  birth_year  death_year  \\\n",
       "0  nm0061671  Mary Ellen Bauder         NaN         NaN   \n",
       "1  nm0061865       Joseph Bauer         NaN         NaN   \n",
       "2  nm0062070         Bruce Baum         NaN         NaN   \n",
       "3  nm0062195       Axel Baumann         NaN         NaN   \n",
       "4  nm0062798        Pete Baxter         NaN         NaN   \n",
       "\n",
       "                                 primary_profession  \\\n",
       "0         miscellaneous,production_manager,producer   \n",
       "1        composer,music_department,sound_department   \n",
       "2                        miscellaneous,actor,writer   \n",
       "3  camera_department,cinematographer,art_department   \n",
       "4  production_designer,art_department,set_decorator   \n",
       "\n",
       "                          known_for_titles  \n",
       "0  tt0837562,tt2398241,tt0844471,tt0118553  \n",
       "1  tt0896534,tt6791238,tt0287072,tt1682940  \n",
       "2  tt1470654,tt0363631,tt0104030,tt0102898  \n",
       "3  tt0114371,tt2004304,tt1618448,tt1224387  \n",
       "4  tt0452644,tt0452692,tt3458030,tt2178256  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING PERSON NAME ID AND PERSON REAL NAME TRANSLATOR KEY\n",
    "# MERGING KEY AND RT_DF TO CORRELATE DIRECTOR TO NAME KEY\n",
    "\n",
    "name_key = file_dict['imdb.name.basics'][['nconst', 'primary_name']]\n",
    "rt_df = rt_df.merge(name_key, left_on = 'director', right_on = 'primary_name')\n",
    "rt_df = rt_df.drop(columns = 'primary_name')\n",
    "\n",
    "# name_key.info()\n",
    "# rt_df.head(1)\n",
    "\n",
    "name_key.head()\n",
    "file_dict['imdb.name.basics'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dict['imdb.title.crew'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0285252</td>\n",
       "      <td>nm0899854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0462036</td>\n",
       "      <td>nm1940585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0835418</td>\n",
       "      <td>nm0151540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0878654</td>\n",
       "      <td>nm0089502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0878654</td>\n",
       "      <td>nm2291498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst   director\n",
       "0  tt0285252  nm0899854\n",
       "2  tt0462036  nm1940585\n",
       "3  tt0835418  nm0151540\n",
       "4  tt0878654  nm0089502\n",
       "4  tt0878654  nm2291498"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING DIRECTOR ID / MOVIE ID KEY FOR MERGING \n",
    "\n",
    "# movie_director_code = file_dict['imdb.title.crew'][['tconst', 'directors']]\n",
    "# type(movie_director_code['directors'][0]) #str\n",
    "# movie_director_code['director'] = movie_director_code['directors'].str.split(',')\n",
    "# movie_director_code.drop(columns = 'directors', inplace = True)\n",
    "# movie_director_code = movie_director_code.explode('director')\n",
    "# movie_director_code = movie_director_code.dropna()\n",
    "# movie_director_code.info()\n",
    "\n",
    "# movie_director_code.head(1)\n",
    "\n",
    "movie_director_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146144"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(file_dict['imdb.title.basics']['runtime_minutes'])#368 unique #146144  total\n",
    "# file_dict['imdb.title.basics']['runtime_minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 130938 entries, 0 to 169259\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   tconst           130938 non-null  object\n",
      " 1   primary_title    130938 non-null  object\n",
      " 2   original_title   130938 non-null  object\n",
      " 3   runtime_minutes  130938 non-null  int64 \n",
      " 4   director         130938 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# TITLE CODE, TITLE NAME, SECOND TITLE NAME, DIRECTOR CODE, RUNTIME \n",
    "# WILL BE MERGING WITH ROTTEN TOMATO CLEANED DATA TO CORRELATE CRITIC RATINGS TO MOVIE TITLES \n",
    "\n",
    "# movie_id_names_time = file_dict['imdb.title.basics'][['tconst', 'primary_title', 'original_title', 'runtime_minutes']]\n",
    "# half_way = movie_id_names_time.merge(movie_director_code, how = 'left', on = 'tconst')\n",
    "# half_way_clean = half_way.dropna()\n",
    "\n",
    "# def float_conv(flt):\n",
    "#     integer = int(flt)\n",
    "#     return integer\n",
    "\n",
    "# half_way_clean['runtime_minutes'] = half_way_clean['runtime_minutes'].apply(float_conv)\n",
    "# type(half_way_clean['runtime_minutes']\n",
    "\n",
    "# len(half_way_clean['runtime_minutes']) #130k\n",
    "half_way_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_dict['imdb.title.basics']['runtime_minutes'].unique().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108, 116, 128, 100, 132, 115,  95,  82, 117,  97, 102, 127,  98,\n",
       "        96, 106, 121, 123, 110,  91, 103, 142,  86,  94,  88, 125, 119,\n",
       "        93, 196, 153, 155, 154, 126, 136, 140, 124, 107,  99, 113, 101,\n",
       "        90, 118, 105, 135,  92, 109,  70, 134, 137, 130, 120, 104, 147,\n",
       "       146, 179,  89, 111, 171, 114,  87, 170,  81, 133, 129,  83, 156,\n",
       "       145, 150, 138,  84, 174, 184,  75, 122, 148,  85,  80, 358,  67,\n",
       "        59, 144, 164, 166, 157, 139, 112, 159, 161, 131,  56, 141, 149,\n",
       "       158])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# half_way_clean[['director', 'runtime_minutes']].drop_duplicates() #127k\n",
    "# (half_way_clean['runtime_minutes'].unique())#91k unique directors 360 unique times 130k total times \n",
    "rt_df['runtime'].unique()\n",
    "\n",
    "# # len(pd.unique(rt_df['nconst']))\n",
    "\n",
    "\n",
    "\n",
    "# len(rt_df['id'].unique())\n",
    "\n",
    "# rt_df['runtime'].value_counts()\n",
    "# half_way_clean['runtime_minutes'][:20]\n",
    "# (rt_df.groupby(['id']).count()['runtime'].unique())\n",
    "\n",
    "# (half_way_clean.groupby(['tconst']).count())#['runtime_minutes'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29275 entries, 0 to 29274\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        29275 non-null  int64  \n",
      " 1   director  29275 non-null  object \n",
      " 2   runtime   29275 non-null  int64  \n",
      " 3   rating    29275 non-null  float64\n",
      " 4   nconst    29275 non-null  object \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "rt_df.info()\n",
    "# half_way_clean.groupby(['director', 'runtime_minutes'], as_index = False).count()[['director', 'runtime_minutes']]\n",
    "# len(half_way_clean[['director', 'runtime_minutes']].drop_duplicates())\n",
    "# pd.unique(rt_df['runtime', 'nconst']\n",
    "# rt_df[['runtime', 'nconst']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [368]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test = rt_df.merge(half_way_clean, left_on = ['runtime', 'nconst'], right_on = ['runtime_minutes', 'director'])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# test.head()\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# test.info()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# test.loc[90:1300]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m test\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcsv_dict\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_imdb_gross_full\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# test = rt_df.merge(half_way_clean, left_on = ['runtime', 'nconst'], right_on = ['runtime_minutes', 'director'])\n",
    "# test.head()\n",
    "# test.info()\n",
    "# len(pd.unique(test['director_y']))\n",
    "# test[['director', 'runtime_minutes']].drop_duplicates()\n",
    "\n",
    "# test.loc[90:1300]\n",
    "\n",
    "test.head()\n",
    "\n",
    "csv_dict.get('tmdb_imdb_gross_full').info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/ZippedData/bom.movie_gross.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [370]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m     10\u001b[0m     df_name\u001b[38;5;241m=\u001b[39mdf_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m     df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m     13\u001b[0m     df_name\u001b[38;5;241m=\u001b[39mdf_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tsv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:686\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    633\u001b[0m     engine_specified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    635\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    636\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m    637\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m     skip_blank_lines\u001b[38;5;241m=\u001b[39mskip_blank_lines,\n\u001b[1;32m    684\u001b[0m )\n\u001b[0;32m--> 686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:452\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    449\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:946\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 946\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:1178\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[43mCParserWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:2008\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols_dtype \u001b[38;5;241m=\u001b[39m _validate_usecols_arg(kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2006\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[0;32m-> 2008\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m   2011\u001b[0m passed_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:382\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:620\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ZippedData/bom.movie_gross.csv.gz'"
     ]
    }
   ],
   "source": [
    "with open ('file_list.txt', 'r') as f:\n",
    "    file_list= f.readlines()\n",
    "    \n",
    "csv_dict = {}\n",
    "\n",
    "for csv in file_list:\n",
    "    file='data/ZippedData/'+csv.strip()\n",
    "    df_name=csv.strip()\n",
    "    if 'csv' in file:\n",
    "        df_name=df_name.split('.csv.gz')[0]\n",
    "        df=pd.read_csv(file, compression='gzip')\n",
    "    elif 'tsv' in file:\n",
    "        df_name=df_name.split('.tsv.gz')[0]\n",
    "        df=pd.read_csv(file, compression='gzip', delimiter='\\t', encoding='latin-1')\n",
    "    else: print(file, \": unkown file!\")\n",
    "    csv_dict[df_name] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dict.get('tmdb_imdb_gross_full').info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGING MOVIE KEYS \n",
    "\n",
    "rt_df = rt_df.merge(name_key, left_on = 'director', right_on = 'primary_name')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('learn-env')",
   "language": "python",
   "name": "python385jvsc74a57bd00386e0ab960921a80f389732ca4b5c334f986e0948b3f6661aa613ff8b30dca4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
